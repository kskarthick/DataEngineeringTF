# DataEngineeringTF
DataEngineering TF Project
Step 1: Create an Azure Account.
Step 2: Create a Resource group.
Step 3: Create a Data Factory capacity account.
Step 4: Log in to the Power BI account.
Step 5: Create a new workspace in the created account.
Step 6: Set the workspace to the fabric capacity.
Step 7: Create a new Pipeline.
Step 8: Create a new Lakehouse.
Step 9: In the Pipeline, create copydata and configure the source file.
Step 10: The Source is retrieved from the SearchAPI and transferred to the destination Lakehouse in the Jsonfile.
Step 11: Next step is to create a notepad in which from the Json file we need to transfer to delta table with pyhton code in Lakehouse with many transfermation steps.
Step 12: Next step is to find the sentiment analysis need to create the another Notepad file to get the final data in the sentiment delta table.
Step 13: Pipeline to need to configure with the copydata,notepad1 and notepad2.
Step 14: Once all data we got in setiment delta table export the data in CSV.
Step 15: Consider CSV file as source for Power BI and develop the Power BI dashboard.
