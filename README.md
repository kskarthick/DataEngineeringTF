# DataEngineeringTF
DataEngineering TF Project

Step 1: Create an Azure Account.

Step 2: Create a Resource group.

Step 3: Create a Data Factory capacity account.

Step 4: Log in to the Power BI account.

Step 5: Create a new workspace in the created account.

Step 6: Set the workspace to the fabric capacity.

Step 7: Create a new Pipeline.

Step 8: Create a new Lakehouse.

Step 9: In the Pipeline, create copydata and configure the source file.

Step 10: The Source is retrieved from the SearchAPI and transferred to the destination Lakehouse in the JSON file.

Step 11: Next step is to create a notepad in which from the Json file we need to transfer to a delta table with Python code in Lakehouse with many transformation steps.

Step 12: The Next step is to find the sentiment analysis needed to create another Notepad file to get the final data in the sentiment delta table.

Step 13: The Pipeline needs to be configured with the copydata,notepad1 and notepad2.

Step 14: Once all the data is in the sentiment delta table, export the data in CSV.

Step 15: Consider the CSV file as a source for Power BI and develop the Power BI dashboard.
